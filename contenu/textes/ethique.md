Éthique
=======

Rapide aperçu des questions éthiques que pose l'avènement de l'intelligence artificielle.

Les valeurs de l'intelligence artificielle
------------------------------------------

Dans [un entretien avec Etienne Klein](https://www.franceculture.fr/emissions/la-conversation-scientifique/lintelligence-peut-elle-devenir-artificielle), Yann Le Cun pose le problème des dangers pour l'humanité d'une I.A. qui aurait des émotions, des objectifs, des motivations, des désirs et serait capable de prendre des décisions. Il propose cette solution :

>  Il faudra entrainer la fonction objectif de la machine de telle manière à ce que ses pulsions et ses valeurs soient alignées sur les valeurs humaines….

Le problème est que les valeurs humaines universelles dont parle Yann le Cun n'existent pas et n'existeront jamais tant qu'il y aura des hommes et des femmes sur la Terre. On peut même affirmer qu'une humanité où tous les individus partageraient rigoureusement les mêmes valeurs ne serait composée que de robots. Je ne partage pas les valeurs de Marc Zuckerberg. Tu ne partages pas celles de Donald Trump. Il ne partage pas celles de Kim Jong Un. Nous trois partageons beaucoup de valeurs mais pas toutes.

Yann Le Cun est dans une impasse théorique. "Les valeurs humaines" est un concept avec autant d'occurrences qu'il y a d'individus sur Terre et il est impossible de définir un ensemble de valeurs approuvées par toute l'humanité. Ce qui risque de se passer, c'est que les robots seront alignés sur les valeurs de leur créateur. Et comme l'I.A est aujourd'hui un business et que l'expérience nous montre que le business ne s'embarrasse pas trop des garanties fondamentales en matière d'éthique et de sécurité sanitaire, on peut douter que les robots œuvrent pour le bien du plus grand nombre.

![](../../ressources/dessin5.png)

Le droit des robots
-------------------

Il n'y a aucune raison de craindre les machines pour ce qu'elles sont. L'I.A. ne peut pas en vouloir à l'humanité. L'auteur de science-fiction Asimov s'énervait contre le syndrome de Frankenstein très présent dans la littérature du début du 20e siècle et qui voulait que systématiquement la créature se retourne contre son créateur. Mais pour rendre possible un univers fictionnel combinant humains et robots sympathiques, Asimov a été amené à formuler [trois lois](https://fr.wikipedia.org/wiki/Trois_lois_de_la_robotique) inscrites matériellement dans l'intelligence de ses robots :

1.   un robot ne peut porter atteinte à un être humain ni, en restant passif, permettre qu'un être humain soit exposé au danger.
2.   un robot doit obéir aux ordres qui lui sont donnés par un être humain, sauf si de tels ordres entrent en conflit avec la première loi
3.   un robot doit protéger son existence tant que cette protection n'entre pas en conflit avec la première ou la deuxième loi.

Toute son œuvre va ensuite consister à mettre ces trois lois à l'épreuve de ses scénarios de romans et de nouvelles ce qui l'amènera à les compléter et les enrichir. La question est de savoir si un procédé littéraire aussi réussi soit-il peut devenir pertinent dans la réalité. Cette démarche de limitation matérielle des robots à travers des lois simplistes ne pourrait-elle pas s'avérer contreproductive et finalement dangereuse pour l'humanité.

Science fiction vs. réalité, humanisme vs. Transhumanisme
---------------------------------------------------------

On note un intérêt croissant pour l'intelligence artificielle depuis le début des années 2010. Les chercheurs, les actionnaires, les entrepreneurs, les artistes et le public s'emballent sans que l'on puisse vraiment savoir qui influence qui. Des periodes similaires sont identifiables dans le passé, notamment durant les années 80 et au début des années 60.

On a vu des concepts de science-fiction délirants prendre la couleur du quotidien et à l'inverse des scientifiques aguerris rater monumentalement leurs prédictions. Mais les prophéties technologiques, qu'elles décrivent un avenir apocalyptique ou édénique, continuent de nous fasciner et influent beaucoup sur l'imaginaire collectif.

De plus, certains de ces prophètes sont surmédiatisés. C'est le cas des pompiers pyromanes que sont Elon Musk (Space X,Tesla) et Ray Kurzweil (Google). Ils prônent la singularité, une accélération de la recherche en matière d'I.A. et de biotechnologie, et en même temps prédisent que ces innovations vont conduire à la fin de l'humanité. Pour eux, la seule solution pour y échapper est non pas de cohabiter avec l'I.A. mais de fusionner avec elle pour éviter qu'elle nous domine. C'est le rêve du transhumanisme, de l'homme augmenté avec, entre autres, de l'électronique implantée dans le cerveau pour bénéficier du pouvoir de l'intelligence artificielle. L'étape suivante est le post-humanisme où le corps disparait et le cerveau est téléchargé dans une machine, une façon simple d'accéder à l'immortalité.

Qui pourra bénéficier de ces technologies extrêmement coûteuses et énergivores ? Ni les paysans du Sahel, ni les pêcheurs du sud du Bangladesh, ni toi, ni moi. On ne s'orienterait donc pas vers une humanité augmentée mais vers deux voire plusieurs humanités dont certaines seront très augmentées, les dominants, et d'autres de plus en plus vulnérables, la bête. L'écart entre les plus pauvres et les plus riches va-t-il grandir à la vitesse des progrès de la technologie ?

---

Continuer la lecture : [**Machines, émotions et darwinisme**](../textes/machines-emotions-et-darwinisme.md)
